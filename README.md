# ETL_clicksign

## ğŸ’» Projeto

Esse projeto roda uma pipeline ETL de um conjunto de dados da US Census Bureau, seguindo as especificaÃ§Ãµes: https://github.com/clicksign/python-dev-test/blob/master/README.md


## ConsideraÃ§Ãµes sobre o projeto

1. Esse projeto executa um script que roda a cada 10 segundos e faz o ETL dos dados Adult.data e Adult.test, que estÃ£o dentro da pasta /data
2. A cada iteraÃ§Ã£o ele processa 1630 registros do conjunto de dados.
3. Enquanto os dados nÃ£o sÃ£o carregados por completo no banco, um arquivo temporÃ¡rio Ã© gerado no mesmo diretÃ³rio, sendo utilizado como um buffer
4. Optei por utilizar o bilioteca schedule para agendamento da execuÃ§Ã£o a cada 10 segundos pela simplicidade
5. TambÃ©m utilizao o SQLAlchemy pela facilidade em inserir dados no banco. (Obs: Utilizo o metoho bulk_insert_mappings() da session do SQLAlchemy pois durante os testes ele apresentar um performance bem superior ao mÃ©todo add())
6. o arquivo ETL.ipynb contÃ©m a anÃ¡lise exploratÃ³rio dos dados. A partir dele que foi desenvolvido toda a lÃ³gica do ETL.
7. Utilizo variÃ¡vel de ambiente para definir o caminho absoluto dos arquivos e os dados do banco. No arquivo .env-example vocÃª pode encontrar como criar um arquivo .env para rodar no seu local (obs: Sem em arquivo .env nÃ£o vai funcionar)


## Os arquivos estÃ£o organizados da seguinte maneira:

- ETL.ipynb -> AnÃ¡lise exploratÃ³ria dos dados
- etl
  - contants.py -> As colunas da tabela como Enum
  - service.py -> principal arquivo, onde Ã© executado toda a lÃ³gica do ETL
- infractructure
  - core
    - models.py -> RepresentaÃ§Ã£o do modelo de dados
    - repository.py -> InsersÃ£o dos dados no banco
    - settings.py -> ContÃ©m algumas variÃ¡veis de configuraÃ§Ãµes
  - database
    - base.py
    - init_db.py -> Inicializa a tabele `adult` no banco
    - session.py -> Engine e session do SQLAlchemy
- script
  - run.py -> Script que roda o ETL a cada 10 segundos


## ğŸš€ Technologies

Este projeto foi desenvolvido com as seguintes tecnologias e ferramentas:
- Python 3.10.8
- Pandas 1.5.2
- Schedule 1.1.0
- SQLAlchemy 1.4.41
- Makefile

O banco de dados utilizado para carregar os dados foi o `postgreSQL`.


## ObservaÃ§Ãµes

Nesse projeto optei por utilizar um ambiente virtual e nÃ£o um conteiner Docker pela facilidade.
E como ele carregada os dados em um banco postgres local, tenha em mente que vocÃª precisa ter um banco postgres rodando localmente.


## â„¹ï¸ Como rodar o projeto

1. Preparando o ambiente:

VocÃª pode usar um [virtualenv](https://virtualenv.pypa.io/en/latest/) para executar o aplicativo localmente.

Virtualenv jÃ¡ estÃ¡ incluÃ­do na biblioteca padrÃ£o do Python3. VocÃª pode criar um ambiente virtual usando o comando abaixo:

```
python3 -m venv venv
```

Ative seu ambiente virtual
```
(Unix ou MacOS) $ source venv/bin/activate
(Windows) ...\> env\Scripts\activate.bat
```

Com o ambiente virtual ativado, instale as dependÃªncias, utilizando o comando abaixo:
```
make install-dependencies
```

NÃ£o esqueÃ§a de criar uma arquivo `.env`. VocÃª pode renomear o arquivo `.env.example` para `.env` e mudar o valor das variÃ¡veis.
O valor da variÃ¡vel BASE_PATH deve ser o caminho da pasta do projeto (no meu caso o meu projeto estÃ¡ dentro de /clicksign)


Rode o script
```
make run-etl
```

Agora vocÃª pode acompanhar pelo terminal a execuÃ§Ã£o do script


## ğŸ“ Versioning

1.0.0

## ğŸ§” Authors

* **Marco Capozzoli**: e-mail: marcocapozzoli90@gmail.com